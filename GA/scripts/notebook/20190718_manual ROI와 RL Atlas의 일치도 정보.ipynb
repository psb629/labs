{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "caudate_dir = '/clmnlab/GA/fmri_data/GA_caudate_ROI/slicer_2/tlrc_resam_group/'\n",
    "\n",
    "file_names = glob.glob(caudate_dir + 'GA*_caudate_resam.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_dir = '/clmnlab/GA/fmri_data/masks/ReinforcemenLearning/roi_201907/03_resam_GA/bilateral/'\n",
    "\n",
    "roi_fname = roi_dir + 'RL_02_Ca_resam.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_img = nilearn.image.load_img(roi_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671.0\n",
      "629.0\n",
      "634.0\n",
      "546.0\n",
      "530.0\n",
      "515.0\n",
      "475.0\n",
      "493.0\n",
      "625.0\n",
      "629.0\n",
      "481.0\n",
      "577.0\n",
      "467.0\n",
      "668.0\n",
      "586.0\n",
      "589.0\n",
      "582.0\n",
      "665.0\n",
      "666.0\n",
      "532.0\n",
      "590.0\n",
      "529.0\n",
      "522.0\n",
      "626.0\n",
      "521.0\n",
      "611.0\n",
      "419.0\n",
      "509.0\n",
      "625.0\n",
      "659.0\n"
     ]
    }
   ],
   "source": [
    "caudate_imgs = []\n",
    "\n",
    "for fname in file_names:\n",
    "    img = nilearn.image.load_img(fname)\n",
    "    print(np.sum(img.get_data()))\n",
    "    caudate_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for img in caudate_imgs:\n",
    "    inter_img = nilearn.image.math_img(img1=roi_img, img2=img, formula='img1 * img2')\n",
    "    result.append((np.sum(inter_img.get_data()), np.sum(img.get_data()), np.sum(roi_img.get_data())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(449.0, 671.0, 662.0),\n",
       " (420.0, 629.0, 662.0),\n",
       " (445.0, 634.0, 662.0),\n",
       " (412.0, 546.0, 662.0),\n",
       " (415.0, 530.0, 662.0),\n",
       " (396.0, 515.0, 662.0),\n",
       " (415.0, 475.0, 662.0),\n",
       " (348.0, 493.0, 662.0),\n",
       " (457.0, 625.0, 662.0),\n",
       " (487.0, 629.0, 662.0),\n",
       " (380.0, 481.0, 662.0),\n",
       " (422.0, 577.0, 662.0),\n",
       " (340.0, 467.0, 662.0),\n",
       " (459.0, 668.0, 662.0),\n",
       " (430.0, 586.0, 662.0),\n",
       " (465.0, 589.0, 662.0),\n",
       " (385.0, 582.0, 662.0),\n",
       " (469.0, 665.0, 662.0),\n",
       " (459.0, 666.0, 662.0),\n",
       " (370.0, 532.0, 662.0),\n",
       " (418.0, 590.0, 662.0),\n",
       " (380.0, 529.0, 662.0),\n",
       " (426.0, 522.0, 662.0),\n",
       " (459.0, 626.0, 662.0),\n",
       " (426.0, 521.0, 662.0),\n",
       " (461.0, 611.0, 662.0),\n",
       " (355.0, 419.0, 662.0),\n",
       " (372.0, 509.0, 662.0),\n",
       " (423.0, 625.0, 662.0),\n",
       " (534.0, 659.0, 662.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual ROI's overlap 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50791854\n",
      "0.48220438\n",
      "0.52291423\n",
      "0.51758796\n",
      "0.53410554\n",
      "0.5070422\n",
      "0.57479227\n",
      "0.43122676\n",
      "0.55060244\n",
      "0.6057214\n",
      "0.4980341\n",
      "0.51652384\n",
      "0.43092522\n",
      "0.52698046\n",
      "0.5256724\n",
      "0.59160304\n",
      "0.44819558\n",
      "0.5466201\n",
      "0.52819335\n",
      "0.44902912\n",
      "0.50119907\n",
      "0.46855733\n",
      "0.5620053\n",
      "0.5536791\n",
      "0.5627477\n",
      "0.567734\n",
      "0.4889807\n",
      "0.46558198\n",
      "0.48958334\n",
      "0.67852604\n"
     ]
    }
   ],
   "source": [
    "for res in result:\n",
    "    non_overlab_count = (res[1] - res[0]) + (res[2] - res[0])\n",
    "    overlab_prob = res[0] / (res[0] + non_overlab_count)\n",
    "    print(overlab_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group ROI's overlap 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_roi = nilearn.image.load_img(caudate_dir + 'group_caudate_resam.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_ratio(inter_count, img1_count, img2_count):\n",
    "    non_overlab_count = (img1_count - inter_count) + (img2_count - inter_count)\n",
    "    overlab_ratio = inter_count / (inter_count + non_overlab_count)\n",
    "    \n",
    "    return overlab_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 threshold: 0.46 (1375 voxels)\n",
      "0.1 threshold: 0.57 (953 voxels)\n",
      "0.2 threshold: 0.59 (798 voxels)\n",
      "0.3 threshold: 0.61 (663 voxels)\n",
      "0.4 threshold: 0.60 (584 voxels)\n",
      "0.5 threshold: 0.58 (514 voxels)\n",
      "0.6 threshold: 0.54 (429 voxels)\n",
      "0.7 threshold: 0.51 (373 voxels)\n",
      "0.8 threshold: 0.45 (319 voxels)\n",
      "0.9 threshold: 0.33 (221 voxels)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 30, 3):\n",
    "    thr_img = nilearn.image.math_img(img1=group_roi, formula='img1>%d' % (i))\n",
    "    \n",
    "    inter_count = np.sum(nilearn.image.math_img(img1=roi_img, img2=thr_img, formula='img1 * img2').get_data())\n",
    "    img1_count = np.sum(thr_img.get_data())\n",
    "    img2_count = np.sum(roi_img.get_data())\n",
    "    \n",
    "    print('%.1f threshold: %.2f (%d voxels)' % ((i / 30), overlap_ratio(inter_count, img1_count, img2_count), img1_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13049.829000000002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.7*2.7*2.7*663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(roi_img.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13030.146000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.7*2.7*2.7*662"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
