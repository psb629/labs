{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import nilearn.image, nilearn.decoding\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TM_dir = '/clmnlab/TM'\n",
    "TM_dir = 'Z:/TM'\n",
    "\n",
    "behav_dir = TM_dir + '/behav_data/'\n",
    "fan_roi_dir = TM_dir + '/fMRI_data/masks/Fan/Fan280/'\n",
    "stats_dir_6 = TM_dir + '/fMRI_data/stats/Reg6_MVPA2_IM_VWM/'\n",
    "stats_dir_7 = TM_dir + '/fMRI_data/stats/Reg7_MVPA3_IM_COY/'\n",
    "preproc_dir = TM_dir + '/fMRI_data/preproc_data/'\n",
    "result_dir = TM_dir\n",
    "Ttest_ROI_mask = TM_dir + '/Clust_mask_binary.nii'\n",
    "\n",
    "subj_list = [\"TML04_PILOT\",\"TML05_PILOT\",\"TML06_PILOT\",\"TML07_PILOT\", \n",
    "            \"TML08_PILOT\",\"TML09_PILOT\",\"TML10_PILOT\",\"TML11_PILOT\",\n",
    "            \"TML12_PILOT\",\"TML13\",\"TML14\",\"TML15\",\"TML16\",\"TML18\",\"TML19\",\"TML20\",\n",
    "            \"TML21\",\"TML22\",\"TML23\",\"TML24\",\"TML25\",\"TML26\",\"TML28\",\"TML29\"]\n",
    "subj_list = [\"TML04_PILOT\"]\n",
    "subj = subj_list[0]\n",
    "\n",
    "freq_range = range(10,20+1,1)\n",
    "freq_c = freq_range[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq_class(freq_range, freq):\n",
    "    #freq_range = range(10,20+1,1)\n",
    "    freqs = [x for x in freq_range]\n",
    "    #print(freqs)\n",
    "    f_mid = int((freqs[0]+freqs[-1])*0.5)\n",
    "    return int(freq - f_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(subj, run):\n",
    "    df = pd.read_csv(behav_dir + subj + '/behav_data_Dis.dat', sep='\\t', header=None)\n",
    "    df.columns=['trial', 'Freq.1', 'ISI1', 'Freq.2', 'ISI2', 'decision', 'correctness', 'RT', 'ISI3']\n",
    "    df['Freq.1.class'] = [np.int64(np.sign(f-freq_c)) for f in df['Freq.1']]\n",
    "    df['Freq.2.class'] = [np.int64(np.sign(f-freq_c)) for f in df['Freq.2']]\n",
    "    df['Freq.other.index'] = [1 if a != 0 else 2 for a in df['Freq.1.class']]\n",
    "    df['Freq.other.class'] = [a+b for a, b in zip(df['Freq.1.class'], df['Freq.2.class'])]\n",
    "    df['answer.index'] = [1 if a>b else 2 for a, b in zip(df['Freq.1'], df['Freq.2'])]\n",
    "    df['decision.index'] = [1 if x == 'before' else (2 if x=='after' else 'NaN') for i, x in enumerate(df['decision'])]\n",
    "    df['Freq.other_decision.class'] = ['NaN' if b=='NaN' else (1 if a==b else -1) for a,b in zip(df['Freq.other.index'],df['decision.index'])]\n",
    "\n",
    "    df['Freq.1.rank'] = [calc_freq_class(freq_range,f) for f in df['Freq.1']]\n",
    "    df['Freq.2.rank'] = [calc_freq_class(freq_range,f) for f in df['Freq.2']]\n",
    "    df['Freq.other.rank'] = [a+b for a, b in zip(df['Freq.1.rank'], df['Freq.2.rank'])]\n",
    "    df['F1<F2.class'] = [int(np.sign(b-a)) for a, b in zip(df['Freq.1'], df['Freq.2'])]\n",
    "\n",
    "    temp = []\n",
    "    trials = [40, 30, 30]\n",
    "    fin = 0\n",
    "    for x in trials:\n",
    "        ini = fin\n",
    "        fin = ini + x\n",
    "        temp.append(df.loc[ini:fin-1])\n",
    "\n",
    "    # Note, Freq.other_answer.class == Freq.other_updown.class\n",
    "    #validation = df['Freq.other_answer.class'] == df['Freq.other.classifier']\n",
    "    #assert validation.all() == True\n",
    "    #assert df['Freq.other_decision.class'].shape[0] == sum(trials)\n",
    "    assert len(temp[run-1]) == trials[run-1]\n",
    "\n",
    "    return temp[run-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_freq_all(subj, run):\n",
    "    df = get_dataframe(subj, run)\n",
    "    df = pd.DataFrame.reset_index(df)\n",
    "\n",
    "    temp = [[df.loc[row,'Freq.1'],df.loc[row,'Freq.2']] for row in range(len(df))]\n",
    "    temp = np.concatenate(temp)\n",
    "    #temp = pd.DataFrame(temp)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_index(subj, run, num_beta, target_beta):\n",
    "## labeling betas of others indices ##\n",
    "    ntrials = [40,30,30]\n",
    "    nbeta = num_beta   # number of betas in one trial\n",
    "    tb = target_beta   # target_beta, (The index starts from 1)\n",
    "    idx = [ nbeta*i + tb[0] for i in range(ntrials[run-1])]\n",
    "        \n",
    "    return np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_beta_image(subj, run):\n",
    "## load nilearn image ##\n",
    "    img = nilearn.image.load_img(stats_dir_7 + '%s/r%02d.LSSout.nii.gz' % (subj, run))\n",
    "    idx = get_label_index(subj, run, 3, [2])\n",
    "    img = nilearn.image.index_img(img, idx)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target(subj, run):\n",
    "## load behavior data and make up them ##\n",
    "    df = get_dataframe(subj, run)\n",
    "    classifier = [ int(2*(idx-1.5)) for idx in df['decision.index'] ]\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### X: neural data / y: answers / group: run number\n",
    "def get_X_y_group(subj, runs):      \n",
    "    \n",
    "    Xs = [load_beta_image(subj, run) for run in runs]\n",
    "    ys = [load_target(subj, run) for run in runs]\n",
    "\n",
    "    group = [\n",
    "        i for i, y in enumerate(ys) for j in range(len(y))\n",
    "    ]\n",
    "    Xs = nilearn.image.concat_imgs(Xs)\n",
    "    ys = np.concatenate(ys)\n",
    "    \n",
    "    assert Xs.shape[-1] == ys.shape[0]\n",
    "    assert ys.shape[0] == len(group)\n",
    "    return Xs, ys, np.array(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_searchlight(full_mask, X, y, group, estimator, group_k, radius, chance_level):\n",
    "    cv = GroupKFold(group_k)\n",
    "\n",
    "    searchlight = nilearn.decoding.SearchLight(\n",
    "    full_mask,\n",
    "    radius=radius,\n",
    "    estimator=estimator,\n",
    "    n_jobs=4,\n",
    "    verbose=False,\n",
    "    cv=cv,\n",
    "    scoring='balanced_accuracy'\n",
    "    )\n",
    "\n",
    "    searchlight.fit(X, y, group)\n",
    "    scores = searchlight.scores_ - chance_level\n",
    "\n",
    "    return nilearn.image.new_img_like(full_mask, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TML04_PILOT's mask_img...\n",
      "Done!\n",
      "Executing searchlight_svc_movement\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-5768f9edda0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Executing searchlight_svc_movement\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msearchlight_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_searchlight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchance_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0msearchlight_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'%s_r%d_movement_%s.nii.gz'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7c3cb713d82e>\u001b[0m in \u001b[0;36mrun_searchlight\u001b[1;34m(full_mask, X, y, group, estimator, group_k, radius, chance_level)\u001b[0m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msearchlight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearchlight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mchance_level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\envs\\test\\lib\\site-packages\\nilearn\\decoding\\searchlight.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, imgs, y, groups)\u001b[0m\n\u001b[0;32m    305\u001b[0m         X, A = _apply_mask_and_get_affinity(\n\u001b[0;32m    306\u001b[0m             \u001b[0mprocess_mask_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             mask_img=self.mask_img)\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\envs\\test\\lib\\site-packages\\nilearn\\input_data\\nifti_spheres_masker.py\u001b[0m in \u001b[0;36m_apply_mask_and_get_affinity\u001b[1;34m(seeds, niimg, radius, allow_overlap, mask_img)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mnearest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnearest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mnearests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_coords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnearest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mnearests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subj in subj_list:\n",
    "    runs = [1,2,3]\n",
    "    fullmask_datum = preproc_dir + subj + '/preprocessed/full_mask.%s.nii.gz' % (subj)\n",
    "    #n_subj = len(subj_list)\n",
    "\n",
    "    # full mask 를 사용하시면 됩니다. 여기에서는 processing time 줄이려고 작은 마스크 가져옴.\n",
    "    print(\"Loading %s's mask_img...\" % (subj))\n",
    "    mask_img = nilearn.image.load_img(fullmask_datum)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    estimator = LinearSVC(max_iter=10000)\n",
    "    estimator_name = 'svc'\n",
    "    radius = 8  # 적절한 크기를 사용하세요.\n",
    "    \n",
    "    #pd.show_versions()\n",
    "\n",
    "    print(\"Executing searchlight_svc_yellow\")\n",
    "    X, y, group = get_X_y_group(subj, runs)\n",
    "    searchlight_img = run_searchlight(mask_img, X, y, group, group_k=3, estimator=estimator, radius=radius, chance_level=1/2)\n",
    "    searchlight_img.to_filename(result_dir + '%s_r%d_yellow_%s.nii.gz' % (subj, radius, estimator_name))\n",
    "\n",
    "    print('%s finished' % (subj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
